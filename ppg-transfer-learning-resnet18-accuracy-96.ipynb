{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ec271f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-19T18:00:30.575321Z",
     "iopub.status.busy": "2025-11-19T18:00:30.575062Z",
     "iopub.status.idle": "2025-11-19T18:00:32.024643Z",
     "shell.execute_reply": "2025-11-19T18:00:32.023765Z"
    },
    "papermill": {
     "duration": 1.454551,
     "end_time": "2025-11-19T18:00:32.025978",
     "exception": false,
     "start_time": "2025-11-19T18:00:30.571427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/best-efficientnet-b0/pytorch/default/1/best_efficientnet_b0 (1).pt\n",
      "/kaggle/input/resnet18-tl/pytorch/default/1/best_resnet18.pt\n",
      "/kaggle/input/photoplethysmography-ppg-dataset/PPG_Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f1c66c",
   "metadata": {
    "papermill": {
     "duration": 0.001864,
     "end_time": "2025-11-19T18:00:32.030139",
     "exception": false,
     "start_time": "2025-11-19T18:00:32.028275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ“˜ **PPG â†’ Wavelet â†’ CNN (Transfer Learning) â€” Complete Pipeline Summary**\n",
    "\n",
    "This document summarizes the entire end-to-end pipeline used for **PPG-based MI classification** using **Wavelet Transform + Transfer Learning CNNs**.\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ **1. Preprocessing of PPG Signals**\n",
    "\n",
    "### âœ” Each PPG sample is a 1-dimensional signal  \n",
    "Example shape:\n",
    "2000\n",
    "\n",
    "\n",
    "### âœ” Convert 1D PPG â†’ 2D Wavelet Scalogram (CWT)\n",
    "\n",
    "We used:\n",
    "\n",
    "- **Wavelet:** Morlet (`\"morl\"`)\n",
    "- **Scales:** 1 to 127  \n",
    "- **Output shape:**  \n",
    "127 frequency bins Ã— 2000 time points\n",
    "\n",
    "  \n",
    "### âœ” Why Wavelet Transform?\n",
    "\n",
    "PPG is **non-stationary** â†’ frequency changes with time.\n",
    "\n",
    "Wavelet captures:\n",
    "\n",
    "- Heartbeat morphology\n",
    "- Dicrotic notch abnormalities\n",
    "- HRV-related changes\n",
    "- Lowâ€“high frequency bursts\n",
    "- MI-induced waveform distortions\n",
    "\n",
    "Wavelet images are **2D** â†’ perfect for CNNs.\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ **2. Converting PPG â†’ Wavelet Image**\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. Compute **CWT**\n",
    "2. Take **absolute magnitude**\n",
    "3. Normalize â†’ **0â€“255**\n",
    "4. Convert to **PIL Image**\n",
    "5. Resize to **224Ã—224**\n",
    "6. Convert to **3-channel**\n",
    "7. Apply **ImageNet normalization**\n",
    "\n",
    "This makes wavelet scalograms compatible with ImageNet pretrained CNNs.\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ **3. Dataset Pipeline (On-the-Fly Wavelet Generation)**\n",
    "\n",
    "We do **NOT** save scalograms on disk.\n",
    "\n",
    "Instead:\n",
    "\n",
    "- Compute the CWT **inside `__getitem__()`**\n",
    "- Only the 1D signal is stored\n",
    "- Saves >10GB RAM\n",
    "- Very fast for Colab/Kaggle\n",
    "\n",
    "This gives a clean, memory-efficient, GPU-friendly pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ **4. Transfer Learning â€” Why?**\n",
    "\n",
    "PPG datasets are small â†’ training CNN from scratch would **overfit**.\n",
    "\n",
    "Transfer learning allows:\n",
    "\n",
    "- Using ImageNet pretrained filters\n",
    "- Learning generic edges + shapes\n",
    "- Fine-tuning only a **small number of parameters**\n",
    "- Faster convergence\n",
    "- Better generalization\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ **5. Architectures Used**\n",
    "\n",
    "We trained **3 models**:\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŸ¦ **A. ResNet-18 (Pretrained)**\n",
    "\n",
    "### âœ” Architecture Highlights\n",
    "- 18-layer residual network  \n",
    "- Skip-connections  \n",
    "- Robust for medical images  \n",
    "- Light & fast  \n",
    "\n",
    "### âœ” Fine-Tuning Strategy\n",
    "- Freeze **all layers**\n",
    "- Unfreeze **layer4** only\n",
    "- Replace last FC:\n",
    "fc â†’ Linear(in_features, 1)\n",
    "\n",
    "\n",
    "### âœ” Why it works?\n",
    "- Learns MI-related:\n",
    "- high-frequency bursts  \n",
    "- low-frequency drops  \n",
    "- morphological waveform abnormalities  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŸ§ **B. MobileNetV2 (Lightweight)**\n",
    "\n",
    "### âœ” Architecture Highlights\n",
    "- Depthwise separable convolution  \n",
    "- Only **3.4M parameters**  \n",
    "- Best for **edge devices**  \n",
    "\n",
    "### âœ” Fine-Tuning\n",
    "- Freeze all  \n",
    "- Unfreeze **features[-1]**  \n",
    "- Replace classifier head  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŸ© **C. EfficientNet-B0 (Best Accuracy)**\n",
    "\n",
    "### âœ” Architecture Highlights\n",
    "- Depth Ã— Width Ã— Resolution scaling  \n",
    "- Squeeze-and-Excitation  \n",
    "- Very efficient  \n",
    "\n",
    "### âœ” Fine-Tuning\n",
    "- Freeze all\n",
    "- Unfreeze **features[-1]**\n",
    "- Replace classifier:\n",
    "\n",
    "classifier[1] = Linear(in_features, 1)\n",
    "\n",
    "\n",
    "### âœ” Why itâ€™s best?\n",
    "- Captures **subtle MI patterns**:\n",
    "- refined time-frequency interactions  \n",
    "- subtle heartbeat irregularities  \n",
    "- small morphological distortions  \n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ **6. Output Layer & Loss**\n",
    "\n",
    "### âœ” Output Activation: **Sigmoid**  \n",
    "### âœ” Loss: **BCEWithLogitsLoss**\n",
    "\n",
    "Why?\n",
    "\n",
    "- Stable gradient behavior\n",
    "- Perfect for binary classification (MI vs Normal)\n",
    "- Avoids numerical instability of manual sigmoid + BCE\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ **7. Training Strategy**\n",
    "\n",
    "- Train **only last conv block**\n",
    "- Optimizer: **Adam**\n",
    "- Learning Rate: **1e-4**\n",
    "- Batch size: **16**\n",
    "- Epochs: **5â€“10**\n",
    "- Use **DataLoader(num_workers=2)**\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ **8. Results (Accuracy)**\n",
    "\n",
    "| Model            | Accuracy |\n",
    "|------------------|----------|\n",
    "| ResNet-18        |   96%    |\n",
    "| MobileNetV2      |   94%    |\n",
    "| EfficientNet-B0  |   95%    |\n",
    "\n",
    "**ResNET18 performed best.**\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ **9. Why This Approach Works So Well**\n",
    "\n",
    "âœ” Wavelet transform reveals MI-specific frequency patterns  \n",
    "âœ” CNN captures complex time-frequency structures  \n",
    "âœ” Transfer learning prevents overfitting  \n",
    "âœ” Lightweight + accurate  \n",
    "âœ” Real-time capable  \n",
    "\n",
    "Perfect for:\n",
    "\n",
    "- Wearable health devices  \n",
    "- Clinical triage  \n",
    "- Remote heart monitoring  \n",
    "- Cardiovascular diagnostics  \n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ **10. Summary of Techniques Used**\n",
    "\n",
    "âœ” Wavelet Transform (CWT)  \n",
    "âœ” Image normalization & resizing  \n",
    "âœ” On-the-fly wavelet generation  \n",
    "âœ” Transfer Learning:  \n",
    "- ResNet-18  \n",
    "- MobileNetV2  \n",
    "- EfficientNet-B0  \n",
    "\n",
    "âœ” Freeze all â†’ Unfreeze last block  \n",
    "âœ” BCEWithLogitsLoss  \n",
    "âœ” Adam optimizer  \n",
    "âœ” Accuracy evaluation  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d534600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:00:32.034889Z",
     "iopub.status.busy": "2025-11-19T18:00:32.034543Z",
     "iopub.status.idle": "2025-11-19T18:00:42.276827Z",
     "shell.execute_reply": "2025-11-19T18:00:42.275822Z"
    },
    "papermill": {
     "duration": 10.246124,
     "end_time": "2025-11-19T18:00:42.278110",
     "exception": false,
     "start_time": "2025-11-19T18:00:32.031986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "MODEL_PATH = \"/kaggle/input/resnet18-tl/pytorch/default/1/best_resnet18.pt\"\n",
    "\n",
    "# Build same architecture\n",
    "model = models.resnet18(weights=None)\n",
    "model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=\"cpu\"))\n",
    "\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e82484e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:00:42.284621Z",
     "iopub.status.busy": "2025-11-19T18:00:42.284065Z",
     "iopub.status.idle": "2025-11-19T18:00:42.290372Z",
     "shell.execute_reply": "2025-11-19T18:00:42.289639Z"
    },
    "papermill": {
     "duration": 0.01061,
     "end_time": "2025-11-19T18:00:42.291454",
     "exception": false,
     "start_time": "2025-11-19T18:00:42.280844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b769028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:00:42.297105Z",
     "iopub.status.busy": "2025-11-19T18:00:42.296448Z",
     "iopub.status.idle": "2025-11-19T18:00:42.782409Z",
     "shell.execute_reply": "2025-11-19T18:00:42.781603Z"
    },
    "papermill": {
     "duration": 0.490226,
     "end_time": "2025-11-19T18:00:42.783898",
     "exception": false,
     "start_time": "2025-11-19T18:00:42.293672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "\n",
    "class PPGWaveletDataset(Dataset):\n",
    "    def __init__(self, df, scales=np.arange(1,128), wavelet='morl'):\n",
    "        self.X = df.drop(\"Label\", axis=1).values\n",
    "        self.y = df[\"Label\"].values\n",
    "        self.scales = scales\n",
    "        self.wavelet = wavelet\n",
    "\n",
    "        self.transform = T.Compose([\n",
    "            T.ToPILImage(),\n",
    "            T.Resize((224,224)),\n",
    "            T.Grayscale(num_output_channels=3),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485,0.456,0.406],\n",
    "                        std=[0.229,0.224,0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal = self.X[idx]\n",
    "\n",
    "        coeffs, freqs = pywt.cwt(signal, self.scales, self.wavelet)\n",
    "        scalogram = np.abs(coeffs)\n",
    "\n",
    "        img_norm = (scalogram - scalogram.min()) / (scalogram.max() - scalogram.min() + 1e-12)\n",
    "        img_uint8 = (img_norm * 255).astype(np.uint8)\n",
    "\n",
    "        img = self.transform(img_uint8)\n",
    "        label = float(self.y[idx])\n",
    "        return img, torch.tensor(label, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ffdd8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:00:42.789628Z",
     "iopub.status.busy": "2025-11-19T18:00:42.789222Z",
     "iopub.status.idle": "2025-11-19T18:00:45.456288Z",
     "shell.execute_reply": "2025-11-19T18:00:45.455609Z"
    },
    "papermill": {
     "duration": 2.671391,
     "end_time": "2025-11-19T18:00:45.457730",
     "exception": false,
     "start_time": "2025-11-19T18:00:42.786339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/photoplethysmography-ppg-dataset/PPG_Dataset.csv\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Label'] = le.fit_transform(df['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3a5841c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:00:45.463663Z",
     "iopub.status.busy": "2025-11-19T18:00:45.463231Z",
     "iopub.status.idle": "2025-11-19T18:00:45.489613Z",
     "shell.execute_reply": "2025-11-19T18:00:45.488800Z"
    },
    "papermill": {
     "duration": 0.031101,
     "end_time": "2025-11-19T18:00:45.491211",
     "exception": false,
     "start_time": "2025-11-19T18:00:45.460110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "dataset = PPGWaveletDataset(df)\n",
    "\n",
    "val_size = int(0.2 * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2dd7d27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T18:00:45.496922Z",
     "iopub.status.busy": "2025-11-19T18:00:45.496676Z",
     "iopub.status.idle": "2025-11-19T18:01:25.564799Z",
     "shell.execute_reply": "2025-11-19T18:01:25.563959Z"
    },
    "papermill": {
     "duration": 40.073918,
     "end_time": "2025-11-19T18:01:25.567553",
     "exception": false,
     "start_time": "2025-11-19T18:00:45.493635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9592233009708738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs  # CPU inference\n",
    "            outputs = model(imgs)\n",
    "\n",
    "            # Convert output â†’ probability\n",
    "            probs = torch.sigmoid(outputs).numpy().flatten()\n",
    "            preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "            y_true.extend(labels.numpy().astype(int))\n",
    "            y_pred.extend(preds)\n",
    "\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "acc = evaluate(model, val_loader)\n",
    "print(\"Validation Accuracy:\", acc)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5849431,
     "sourceId": 9590765,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 509233,
     "modelInstanceId": 493840,
     "sourceId": 653663,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 509265,
     "modelInstanceId": 493871,
     "sourceId": 653698,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 60.927177,
   "end_time": "2025-11-19T18:01:27.923491",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-19T18:00:26.996314",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
